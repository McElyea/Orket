name: Quality

on:
  push:
    branches: [main]
  pull_request:

jobs:
  architecture_gates:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          python -m pip install -e ".[dev]"

      - name: Enforce dependency direction rules
        run: |
          python scripts/check_dependency_direction.py --legacy-edge-enforcement fail

      - name: Audit OS registry/spec sync
        run: |
          python scripts/audit_registry.py

      - name: Enforce kernel sovereign gate
        run: |
          python -m pytest -q tests/kernel/v1

      - name: Enforce kernel API interface boundary tests
        run: |
          python -m pytest -q tests/interfaces/test_api_kernel_lifecycle.py

      - name: Enforce kernel fire-drill suite
        run: |
          python scripts/run_kernel_fire_drill.py

      - name: Enforce TS digest parity gate
        run: |
          npm test --prefix conformance/ts

      - name: Enforce digest vectors are committed truth (no CI overwrite)
        run: |
          python scripts/gen_digest_vectors.py --out /tmp/digest-v1.json
          diff -u tests/kernel/v1/vectors/digest-v1.json /tmp/digest-v1.json

      - name: Enforce volatility boundary script
        run: |
          python scripts/check_volatility_boundaries.py

      - name: Enforce volatility boundary tests
        run: |
          python -m pytest -q tests/platform/test_architecture_volatility_boundaries.py

      - name: Build retention dry-run plan
        run: |
          python scripts/retention_plan.py --out benchmarks/results/retention_plan.json

      - name: Enforce retention policy safety
        run: |
          python scripts/check_retention_policy.py --plan benchmarks/results/retention_plan.json --out benchmarks/results/retention_policy_check.json --require-safety

      - name: Enforce offline capability matrix contract
        run: |
          python scripts/check_offline_matrix.py --require-default-offline --out benchmarks/results/offline_matrix_check.json

      - name: Enforce docs gate contract
        run: |
          python scripts/docs_lint.py --project core-pillars --strict --json

      - name: Enforce roadmap metrics (quick gate)
        run: |
          python scripts/check_roadmap_metrics.py --quick

      - name: Validate prompt assets
        run: |
          python -m orket.interfaces.prompts_cli --root . validate --json

      - name: Smoke resolve canonical prompt
        run: |
          python -m orket.interfaces.prompts_cli --root . resolve --role architect --dialect generic --selection-policy stable

      - name: Smoke diff prompt policies
        run: |
          python -m orket.interfaces.prompts_cli --root . diff --role architect --dialect generic --left-policy stable --right-policy canary

      - name: Enforce line-ending normalization
        run: |
          git add --renormalize .
          if ! git diff --cached --quiet; then
            echo "Line ending normalization drift detected:"
            git diff --cached --name-only
            exit 1
          fi

  quality:
    runs-on: ubuntu-latest
    needs: architecture_gates
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          python -m pip install -e ".[dev]"

      - name: Run tests with coverage
        run: pytest tests/ --cov=orket --cov-fail-under=60

      - name: Ruff lint
        run: ruff check orket/

      - name: Mypy type check
        run: mypy orket/ --ignore-missing-imports

      - name: Enforce datetime.now UTC usage
        run: |
          if grep -R --line-number "datetime.now()" orket --include="*.py" | grep -v "now(UTC)"; then
            echo "Found disallowed datetime.now() usage"
            exit 1
          fi

      - name: Enforce dependency direction rules
        run: |
          python scripts/check_dependency_direction.py --legacy-edge-enforcement fail

      - name: Enforce volatility boundary script
        run: |
          python scripts/check_volatility_boundaries.py

      - name: Build retention dry-run plan
        run: |
          python scripts/retention_plan.py --out benchmarks/results/retention_plan.json

      - name: Enforce retention policy safety
        run: |
          python scripts/check_retention_policy.py --plan benchmarks/results/retention_plan.json --out benchmarks/results/retention_policy_check.json --require-safety

      - name: Enforce offline capability matrix contract
        run: |
          python scripts/check_offline_matrix.py --require-default-offline --out benchmarks/results/offline_matrix_check.json

      - name: Enforce docs gate contract
        run: |
          python scripts/docs_lint.py --project core-pillars --strict --json

      - name: Enforce roadmap pytest metrics
        run: |
          python scripts/check_roadmap_metrics.py

      - name: Enforce memory determinism contract smoke
        run: |
          mkdir -p benchmarks/results/memory
          python - <<'PY'
          import json
          from pathlib import Path

          trace = {
              "run_id": "quality-memory-run",
              "workflow_id": "quality-memory-workflow",
              "memory_snapshot_id": "snapshot-0",
              "visibility_mode": "read_only",
              "model_config_id": "model-config",
              "policy_set_id": "policy-set",
              "determinism_trace_schema_version": "memory.determinism_trace.v1",
              "events": [
                  {
                      "event_id": "evt-0",
                      "index": 0,
                      "role": "coder",
                      "interceptor": "before_prompt",
                      "decision_type": "prompt_build",
                      "tool_calls": [],
                      "guardrails_triggered": [],
                      "retrieval_event_ids": ["ret-0"],
                  }
              ],
          }
          retrieval = {
              "events": [
                  {
                      "retrieval_event_id": "ret-0",
                      "run_id": "quality-memory-run",
                      "event_id": "evt-0",
                      "policy_id": "retrieval-policy",
                      "policy_version": "v1",
                      "query_normalization_version": "json-v1",
                      "query_fingerprint": "abc123",
                      "retrieval_mode": "text_to_vector",
                      "candidate_count": 1,
                      "selected_records": [],
                      "applied_filters": {},
                      "retrieval_trace_schema_version": "memory.retrieval_trace.v1",
                  }
              ]
          }
          trace_path = Path("benchmarks/results/memory/memory_trace_fixture.json")
          retrieval_path = Path("benchmarks/results/memory/memory_retrieval_trace_fixture.json")
          trace_path.write_text(json.dumps(trace, indent=2) + "\n", encoding="utf-8")
          retrieval_path.write_text(json.dumps(retrieval, indent=2) + "\n", encoding="utf-8")
          PY
          python scripts/check_memory_determinism.py \
            --trace benchmarks/results/memory/memory_trace_fixture.json \
            --retrieval-trace benchmarks/results/memory/memory_retrieval_trace_fixture.json \
            --out benchmarks/results/memory/memory_determinism_check.json
          python scripts/compare_memory_determinism.py \
            --left benchmarks/results/memory/memory_trace_fixture.json \
            --right benchmarks/results/memory/memory_trace_fixture.json \
            --left-retrieval benchmarks/results/memory/memory_retrieval_trace_fixture.json \
            --right-retrieval benchmarks/results/memory/memory_retrieval_trace_fixture.json \
            --out benchmarks/results/memory/memory_determinism_compare.json

      - name: Enforce replay artifact drift comparator smoke
        run: |
          mkdir -p benchmarks/results/replay
          python - <<'PY'
          import json
          from pathlib import Path

          left = {
              "contract_version": "core_pillars/replay_artifact/v1",
              "recorded_at": "2026-02-24T00:00:00+00:00",
              "artifact_id": "a" * 64,
              "command": "api_add",
              "request": {"name": "users", "schema_path": "users.yaml"},
              "result": {"ok": True, "code": "OK", "message": "Applied"},
          }
          right = {
              "contract_version": "core_pillars/replay_artifact/v1",
              "recorded_at": "2026-02-24T01:00:00+00:00",
              "artifact_id": "b" * 64,
              "command": "api_add",
              "request": {"name": "users", "schema_path": "users.yaml"},
              "result": {"ok": True, "code": "OK", "message": "Applied"},
          }
          left_path = Path("benchmarks/results/replay/replay_left_fixture.json")
          right_path = Path("benchmarks/results/replay/replay_right_fixture.json")
          left_path.write_text(json.dumps(left, indent=2) + "\n", encoding="utf-8")
          right_path.write_text(json.dumps(right, indent=2) + "\n", encoding="utf-8")
          PY
          python scripts/compare_replay_artifacts.py \
            --left benchmarks/results/replay/replay_left_fixture.json \
            --right benchmarks/results/replay/replay_right_fixture.json \
            --out benchmarks/results/replay/replay_drift_compare.json

      - name: Enforce skill contract smoke
        run: |
          mkdir -p benchmarks/results/skills
          python - <<'PY'
          import json
          from pathlib import Path

          manifest = {
              "skill_contract_version": "1.0.5",
              "skill_id": "quality.skill.demo",
              "skill_version": "1.0.0",
              "description": "Quality smoke skill contract fixture",
              "manifest_digest": "sha256:abc123",
              "entrypoints": [
                  {
                      "entrypoint_id": "write-main",
                      "runtime": "python",
                      "runtime_version": "3.11.0",
                      "command": "python run.py",
                      "working_directory": ".",
                      "input_schema": {},
                      "output_schema": {},
                      "error_schema": {},
                      "args_fingerprint_fields": ["input.path"],
                      "result_fingerprint_fields": ["result.ok"],
                      "side_effect_fingerprint_fields": [],
                      "requested_permissions": {"filesystem": ["write"]},
                      "required_permissions": {"filesystem": ["write"]},
                      "tool_profile_id": "write_file",
                      "tool_profile_version": "1.0.0",
                  }
              ],
          }
          out = Path("benchmarks/results/skills/skill_contract_fixture.json")
          out.write_text(json.dumps(manifest, indent=2) + "\n", encoding="utf-8")
          PY
          python scripts/check_skill_contracts.py \
            --manifest benchmarks/results/skills/skill_contract_fixture.json \
            --out benchmarks/results/skills/skill_contract_check.json

      - name: Build monolith variant matrix plan
        run: |
          python scripts/run_monolith_variant_matrix.py --out benchmarks/results/monolith_variant_matrix.json

      - name: Enforce monolith readiness gate policy
        run: |
          python scripts/check_monolith_readiness_gate.py --matrix benchmarks/results/monolith_variant_matrix.json --policy model/core/contracts/monolith_readiness_policy.json --allow-plan-only

      - name: Evaluate microservices unlock checklist
        run: |
          python scripts/check_microservices_unlock.py --matrix benchmarks/results/monolith_variant_matrix.json --readiness-policy model/core/contracts/monolith_readiness_policy.json --unlock-policy model/core/contracts/microservices_unlock_policy.json --live-report benchmarks/results/live_acceptance_patterns.json --out benchmarks/results/microservices_unlock_check.json

      - name: Evaluate gitea state pilot readiness
        run: |
          ORKET_STATE_BACKEND_MODE=gitea ORKET_ENABLE_GITEA_STATE_PILOT=true ORKET_GITEA_URL=https://gitea.example.local ORKET_GITEA_TOKEN=ci-token ORKET_GITEA_OWNER=orket ORKET_GITEA_REPO=orket \
          python scripts/check_gitea_state_pilot_readiness.py --out benchmarks/results/gitea_state_pilot_readiness.json --require-ready

      - name: Evaluate gitea state hardening gate
        run: |
          python scripts/check_gitea_state_hardening.py --execute --out benchmarks/results/gitea_state_hardening_check.json --require-ready

      - name: Evaluate gitea phase3 readiness
        run: |
          python scripts/check_gitea_state_phase3_readiness.py --execute --pilot-readiness benchmarks/results/gitea_state_pilot_readiness.json --hardening-readiness benchmarks/results/gitea_state_hardening_check.json --out benchmarks/results/gitea_state_phase3_readiness.json --require-ready

      - name: Build architecture pilot matrix plan
        run: |
          python scripts/run_architecture_pilot_matrix.py --out benchmarks/results/architecture_pilot_matrix.json

      - name: Run benchmark suite scoring smoke
        run: |
          python scripts/run_benchmark_suite.py --task-bank benchmarks/task_bank/v1/tasks.json --policy model/core/contracts/benchmark_scoring_policy.json --runs 1 --venue standard --flow default --runner-template 'python scripts/determinism_control_runner.py --task {task_file} --venue {venue} --flow {flow}' --raw-out benchmarks/results/benchmark_determinism_report.json --scored-out benchmarks/results/benchmark_scored_report.json

      - name: Enforce orchestration overhead telemetry consistency
        run: |
          python scripts/check_orchestration_overhead_consistency.py --report benchmarks/results/benchmark_determinism_report.json --out benchmarks/results/orchestration_overhead_consistency.json

      - name: Enforce telemetry lane/profile fields
        run: |
          python scripts/check_telemetry_artifact_fields.py --report benchmarks/results/benchmark_determinism_report.json --out benchmarks/results/telemetry_artifact_fields_check.json

      - name: Enforce benchmark scoring gate
        run: |
          python scripts/check_benchmark_scoring_gate.py --scored-report benchmarks/results/benchmark_scored_report.json --policy model/core/contracts/benchmark_scoring_policy.json --out benchmarks/results/benchmark_scoring_gate.json --require-thresholds

      - name: Validate prompt assets
        run: |
          python -m orket.interfaces.prompts_cli --root . validate --json

      - name: Smoke resolve canonical prompt
        run: |
          python -m orket.interfaces.prompts_cli --root . resolve --role architect --dialect generic --selection-policy stable

      - name: Enforce line-ending normalization
        run: |
          git add --renormalize .
          if ! git diff --cached --quiet; then
            echo "Line ending normalization drift detected:"
            git diff --cached --name-only
            exit 1
          fi

      - name: Upload load evidence artifacts
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: load-evidence-${{ github.run_id }}
          path: benchmarks/results/*.json
          if-no-files-found: warn

  product_quality:
    runs-on: ubuntu-latest
    needs: architecture_gates
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          python -m pip install -e ".[dev]"

      - name: Run product suite (explicit scope when present)
        run: |
          if [ -d "product/sneaky_price_watch/tests" ]; then
            PYTHONPATH=product/sneaky_price_watch pytest product/sneaky_price_watch/tests -q
          else
            echo "product/sneaky_price_watch/tests not present; suite intentionally excluded."
          fi

  docker_smoke:
    runs-on: ubuntu-latest
    needs: [quality, product_quality]
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Build image
        run: docker build -t orket:${{ github.sha }} .

      - name: Start container
        run: |
          docker run -d --name orket-smoke -p 8082:8082 orket:${{ github.sha }}

      - name: Probe health endpoint
        run: |
          for i in $(seq 1 30); do
            if curl -sf http://127.0.0.1:8082/health >/dev/null; then
              echo "Health probe succeeded"
              exit 0
            fi
            sleep 2
          done
          echo "Health probe failed"
          docker logs orket-smoke || true
          exit 1

      - name: Cleanup container
        if: always()
        run: |
          docker rm -f orket-smoke || true

  migration_smoke:
    runs-on: ubuntu-latest
    needs: [quality, product_quality]
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          python -m pip install -e ".[dev]"

      - name: Bootstrap runtime/webhook schemas
        run: |
          python - <<'PY'
          import asyncio
          from pathlib import Path
          from orket.infrastructure.async_card_repository import AsyncCardRepository
          from orket.services.webhook_db import WebhookDatabase

          async def main():
              repo = AsyncCardRepository(".ci/runtime.db")
              await repo.get_by_build("_migration_smoke_bootstrap_")
              webhook = WebhookDatabase(Path(".ci/webhook.db"))
              await webhook.get_active_prs()

          asyncio.run(main())
          print("Schema bootstrap completed")
          PY

      - name: Run migration smoke
        run: |
          python scripts/run_migrations.py --runtime-db .ci/runtime.db --webhook-db .ci/webhook.db

      - name: Validate migration tables
        run: |
          python - <<'PY'
          import sqlite3
          for db in [".ci/runtime.db", ".ci/webhook.db"]:
              conn = sqlite3.connect(db)
              cur = conn.cursor()
              cur.execute("SELECT COUNT(*) FROM _schema_migrations")
              count = cur.fetchone()[0]
              if count < 1:
                  raise SystemExit(f"No migrations recorded for {db}")
              conn.close()
          print("Migration smoke validation passed")
          PY
