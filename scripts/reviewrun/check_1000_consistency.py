from __future__ import annotations

import argparse
import json
from pathlib import Path


def main() -> int:
    parser = argparse.ArgumentParser(description="Validate ReviewRun 1000 consistency report.")
    parser.add_argument(
        "--report",
        type=str,
        default="benchmarks/results/reviewrun_consistency_1000.json",
        help="Path to report generated by run_1000_consistency.py",
    )
    parser.add_argument("--expected-runs", type=int, default=1000, help="Expected number of runs checked.")
    args = parser.parse_args()

    report_path = Path(args.report).resolve()
    if not report_path.is_file():
        print(json.dumps({"ok": False, "error": "report_not_found", "report": str(report_path)}, indent=2))
        return 2

    payload = json.loads(report_path.read_text(encoding="utf-8"))
    issues: list[str] = []

    if not bool(payload.get("ok")):
        issues.append("report.ok is false")
    consistency = payload.get("consistency") if isinstance(payload.get("consistency"), dict) else {}
    if int(consistency.get("runs_checked") or 0) != int(args.expected_runs):
        issues.append(
            f"runs_checked mismatch: expected={int(args.expected_runs)} actual={int(consistency.get('runs_checked') or 0)}"
        )
    baseline = consistency.get("baseline_signature") if isinstance(consistency.get("baseline_signature"), dict) else {}
    snapshot_digest = str(baseline.get("snapshot_digest") or "")
    policy_digest = str(baseline.get("policy_digest") or "")
    if not snapshot_digest.startswith("sha256:"):
        issues.append("baseline snapshot_digest missing sha256: prefix")
    if not policy_digest.startswith("sha256:"):
        issues.append("baseline policy_digest missing sha256: prefix")
    if not str(baseline.get("deterministic_lane_version") or "").strip():
        issues.append("baseline deterministic_lane_version missing")
    if consistency.get("mismatch") not in (None, {}):
        issues.append("mismatch payload is present")
    default_run = payload.get("default_run") if isinstance(payload.get("default_run"), dict) else {}
    strict_run = payload.get("strict_run") if isinstance(payload.get("strict_run"), dict) else {}
    strict_replay = payload.get("strict_replay") if isinstance(payload.get("strict_replay"), dict) else {}
    default_sig = default_run.get("signature") if isinstance(default_run.get("signature"), dict) else {}
    strict_sig = strict_run.get("signature") if isinstance(strict_run.get("signature"), dict) else {}
    replay_sig = strict_replay.get("signature") if isinstance(strict_replay.get("signature"), dict) else {}
    if not bool(strict_replay.get("parity_with_strict")):
        issues.append("strict replay parity failed")
    if int(len(list(strict_sig.get("findings") or []))) <= 0:
        issues.append("strict run has no findings")
    if not isinstance(strict_run.get("strict_policy"), dict):
        issues.append("strict policy payload missing")
    if not str(default_sig.get("decision") or "").strip():
        issues.append("default decision missing")
    if not str(strict_sig.get("decision") or "").strip():
        issues.append("strict decision missing")
    if strict_sig != replay_sig:
        issues.append("strict and replay signatures differ")
    scenario = str(payload.get("scenario") or "")
    strict_findings = list(strict_sig.get("findings") or [])
    if scenario in {"auth_insecure", "secrets_sha1"}:
        for finding in strict_findings:
            if str(finding.get("code") or "") != "PATTERN_MATCHED":
                continue
            if not str(finding.get("path") or "").strip():
                issues.append("PATTERN_MATCHED finding missing path")
                break
            span = finding.get("span") if isinstance(finding.get("span"), dict) else {}
            if int(span.get("start") or 0) <= 0:
                issues.append("PATTERN_MATCHED finding missing positive span.start")
                break
    truncation_check = payload.get("truncation_check") if isinstance(payload.get("truncation_check"), dict) else {}
    if scenario == "truncation_bounds":
        if not bool(truncation_check.get("ok")):
            issues.append("truncation_check.ok is false")
        if not bool(truncation_check.get("diff_truncated")):
            issues.append("truncation_check.diff_truncated is false")
        if not bool(truncation_check.get("digests_differ")):
            issues.append("truncation_check.digests_differ is false")

    result = {
        "ok": len(issues) == 0,
        "report": str(report_path),
        "expected_runs": int(args.expected_runs),
        "issues": issues,
        "summary": {
            "runs_checked": int(consistency.get("runs_checked") or 0),
            "default_decision": str(default_sig.get("decision") or ""),
            "strict_decision": str(strict_sig.get("decision") or ""),
            "strict_findings_count": len(list(strict_sig.get("findings") or [])),
            "strict_replay_parity": bool(strict_replay.get("parity_with_strict")),
            "scenario": scenario,
        },
    }
    print(json.dumps(result, indent=2, ensure_ascii=False))
    return 0 if result["ok"] else 1


if __name__ == "__main__":
    raise SystemExit(main())
